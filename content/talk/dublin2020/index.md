+++
title = "Trinity College Dublin invited lecture in _Deep Learning Meets Neuroscience_ series"

# Schedule page publish date (NOT talk date).
publishDate = 2017-01-01T00:00:00

# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors = ["Katherine R. Storrs"]

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date = 2020-02-19T17:00:00
date_end = 2020-02-19T18:00:00
all_day = false

# Location of event.
location = "Lecture hall LB11, Lloyd Building, Trinity College Dublin"

# Name of event and optional event URL.
event = "Unsupervised learning predicts human perception and misperception of material properties"
event_url = "https://www.cusacklab.org/seminars.html"

# Abstract. What's your talk about?
abstract = "I will talk about two projects in which we use unsupervised deep learning, combined with large computer-rendered stimulus sets, as a framework to understand how brains learn rich scene representations without ground-truth world information. By learning to generate novel images, or learning to predict the next frame in video sequences, our models spontaneously learn to cluster images according to underlying scene properties such as illumination, shape, and material. We probe the models' representation of material gloss in detail and find that they excellently predict human-perceived glossiness for novel surfaces and for network-generated images. Strikingly, the networks also correctly predict known failures of gloss perception on an image-by-image basis – for example, that bumpier surfaces tend to appear glossier than flatter ones, even when made of identical material. A supervised DNN and several other control models fail. Perceptual dimensions, like 'glossiness,' that appear to estimate properties of the physical world, can emerge spontaneously by learning to efficiently encode sensory data – indeed, unsupervised learning principles may account for a large number of perceptual dimensions in vision and beyond!"

# Summary. An optional shortened abstract.
summary = ""

# Is this a featured talk? (true/false)
featured = true

# Tags (optional).
#   Set `tags = []` for no tags, or use the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags = ["display"]

# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references 
#   `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides = ""

# Optional filename of your slides within your talk folder or a URL.
url_slides = ""

# Projects (optional).
#   Associate this talk with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["deep-learning"]` references 
#   `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects = []

# Links (optional).
url_pdf = ""
url_video = ""
url_code = ""

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
[image]
  # Caption (optional)
  caption = ""

  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point = "Left"
+++
